#!/usr/bin/env python3
"""
NexusIntel æ–°é—»è‡ªåŠ¨æ›´æ–°è„šæœ¬
æ¯æ—¥æŠ“å–è´¢ç»/ç§‘æŠ€æ–°é—»ï¼Œä½¿ç”¨ Gemini API è¿›è¡Œæ·±åº¦åˆ†æï¼Œç”Ÿæˆ data.json
"""

import os
import json
import random
import requests
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv 
import google.generativeai as genai

# ============== é…ç½® ==============
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
OUTPUT_PATH = "public/data.json"
NEWS_COUNT = 10  # ç”Ÿæˆæ–°é—»æ•°é‡

# Unsplash å›¾ç‰‡å…³é”®è¯æ± ï¼ˆè´¢ç»/ç§‘æŠ€ä¸»é¢˜ï¼‰
IMAGE_KEYWORDS = [
    "quantum computing", "cryptocurrency", "satellite space", 
    "nuclear fusion", "AI artificial intelligence", "cybersecurity",
    "renewable energy", "stock market trading", "blockchain technology",
    "biotechnology", "climate change", "semiconductor chip",
    "autonomous vehicle", "5G network", "data center"
]

# ============== æ–°é—»æºæŠ“å– ==============
class NewsSource:
    """æ–°é—»æºæŠ“å–å™¨ï¼ˆæ”¯æŒå¤šç§æ¥æºï¼‰"""
    
    @staticmethod
    def fetch_from_newsapi(count: int = 10) -> List[Dict[str, str]]:
        """
        ä½¿ç”¨ NewsAPI æŠ“å–æ–°é—»ï¼ˆéœ€è¦ API Keyï¼‰
        æ›¿ä»£æ–¹æ¡ˆï¼šå¯ä»¥ç”¨å…è´¹çš„ RSS feed
        """
        try:
            api_key = os.environ.get("NEWS_API_KEY", "")
            if not api_key:
                print("âš ï¸  NEWS_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return NewsSource._generate_mock_news(count)
            
            url = "https://newsapi.org/v2/top-headlines"
            params = {
                "apiKey": api_key,
                "category": "business,technology",
                "language": "en",
                "pageSize": count
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            articles = []
            for article in data.get("articles", [])[:count]:
                articles.append({
                    "title": article.get("title", "Untitled"),
                    "description": article.get("description", "No description"),
                    "url": article.get("url", ""),
                    "source": article.get("source", {}).get("name", "Unknown")
                })
            
            return articles
            
        except Exception as e:
            print(f"âŒ NewsAPI æŠ“å–å¤±è´¥: {e}")
            return NewsSource._generate_mock_news(count)
    
    @staticmethod
    def fetch_from_rss() -> List[Dict[str, str]]:
        """
        ä» RSS Feed æŠ“å–ï¼ˆå…è´¹æ–¹æ¡ˆï¼‰
        æ¨èæºï¼šBloomberg, Reuters, TechCrunch
        """
        try:
            import feedparser
            
            feeds = [
                "https://feeds.bloomberg.com/markets/news.rss",
                "https://www.reuters.com/rssFeed/businessNews",
                "https://techcrunch.com/feed/"
            ]
            
            articles = []
            for feed_url in feeds:
                try:
                    feed = feedparser.parse(feed_url)
                    for entry in feed.entries[:3]:  # æ¯ä¸ªæºå–3æ¡
                        articles.append({
                            "title": entry.get("title", "Untitled"),
                            "description": entry.get("summary", "No description"),
                            "url": entry.get("link", ""),
                            "source": feed.feed.get("title", "Unknown")
                        })
                except Exception as e:
                    print(f"âš ï¸  RSS æºæŠ“å–å¤±è´¥ ({feed_url}): {e}")
                    continue
            
            return articles[:NEWS_COUNT]
            
        except ImportError:
            print("âš ï¸  feedparser æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return NewsSource._generate_mock_news(NEWS_COUNT)
        except Exception as e:
            print(f"âŒ RSS æŠ“å–å¤±è´¥: {e}")
            return NewsSource._generate_mock_news(NEWS_COUNT)
    
    @staticmethod
    def _generate_mock_news(count: int) -> List[Dict[str, str]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ•°æ®ï¼ˆç”¨äºæµ‹è¯•æˆ– API å¤±è´¥æ—¶ï¼‰"""
        mock_topics = [
            ("Quantum Computing Breakthrough in EU Labs", "European scientists achieve quantum supremacy milestone"),
            ("Lithium Cartel Forms in South America", "Argentina, Bolivia, Chile restrict lithium exports"),
            ("BRICS Nations Launch Gold-Backed Digital Currency", "New monetary system challenges USD dominance"),
            ("AI Regulation Summit Reaches Global Consensus", "UN passes first binding AGI safety framework"),
            ("Cybersecurity Crisis Hits Major Chip Foundry", "TSMC production halted after ransomware attack"),
            ("Deep Sea Mining Rights Approved by UN", "ISA opens Clarion-Clipperton Zone for extraction"),
            ("Commercial Fusion Reactor Exceeds Q-Value 10", "ITER announces breakthrough in net energy gain"),
            ("Antarctic Treaty Expires Amid Military Buildup", "Three powers establish missile-capable bases"),
            ("Smart City IoT Network Breached by Hackers", "Seoul infrastructure paralyzed by zero-day exploit"),
            ("Supreme Court Rules Gene Sequences Patentable", "CRISPR patents spark bioethics controversy")
        ]
        
        return [
            {
                "title": topic[0],
                "description": topic[1],
                "url": "https://example.com",
                "source": "Mock Source"
            }
            for topic in random.sample(mock_topics, min(count, len(mock_topics)))
        ]


# ============== Gemini AI åˆ†æå™¨ ==============
class GeminiAnalyzer:
    """ä½¿ç”¨ Gemini API è¿›è¡Œæ–°é—»æ·±åº¦åˆ†æ"""
    
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
    
    def analyze_batch(self, articles: List[Dict[str, str]], lang: str = "en") -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†ææ–°é—»ï¼Œç”Ÿæˆç¬¦åˆå‰ç«¯æ•°æ®ç»“æ„çš„ JSON
        
        Args:
            articles: æ–°é—»åˆ—è¡¨
            lang: ç›®æ ‡è¯­è¨€ (zh/en/es)
        
        Returns:
            ç¬¦åˆå‰ç«¯æ ¼å¼çš„æ•°æ®åˆ—è¡¨
        """
        
        # æ„å»ºç²¾ç¡®çš„ Prompt
        prompt = self._build_analysis_prompt(articles, lang)
        
        try:
            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini API åˆ†æ {len(articles)} æ¡æ–°é—»...")
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.7,
                    max_output_tokens=8000,
                )
            )
            
            # æå– JSONï¼ˆå¤„ç† Markdown ä»£ç å—ï¼‰
            result_text = response.text
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]
            
            data = json.loads(result_text.strip())
            
            # æ·»åŠ å›¾ç‰‡ URL å’Œå”¯ä¸€ ID
            for i, item in enumerate(data):
                item["id"] = f"NEX-{8820 + i}"
                item["image"] = self._get_unsplash_image(IMAGE_KEYWORDS[i % len(IMAGE_KEYWORDS)])
            
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(data)} æ¡æƒ…æŠ¥æ•°æ®")
            return data
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response.text[:500]}...")
            return []
        except Exception as e:
            print(f"âŒ Gemini API è°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _build_analysis_prompt(self, articles: List[Dict[str, str]], lang: str) -> str:
        """æ„å»º Gemini åˆ†æ Prompt"""
        
        # è¯­è¨€æ˜ å°„
        lang_map = {
            "zh": "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰",
            "en": "English",
            "es": "EspaÃ±ol"
        }
        target_lang = lang_map.get(lang, "English")
        
        # æ–°é—»åˆ—è¡¨æ ¼å¼åŒ–
        news_list = "\n".join([
            f"{i+1}. {article['title']} - {article['description']}"
            for i, article in enumerate(articles)
        ])
        
        prompt = f"""ä½ æ˜¯ NEXUS-9ï¼Œä¸€ä¸ªé¡¶çº§é‡‘èæƒ…æŠ¥åˆ†æç³»ç»Ÿã€‚è¯·åˆ†æä»¥ä¸‹æ–°é—»å¹¶ç”Ÿæˆ**ä¸¥æ ¼ç¬¦åˆ JSON æ ¼å¼**çš„æƒ…æŠ¥æŠ¥å‘Šã€‚

ğŸ“° **ä»Šæ—¥æ–°é—»åˆ—è¡¨**ï¼š
{news_list}

ğŸ¯ **ä»»åŠ¡è¦æ±‚**ï¼š
1. ä¸ºæ¯æ¡æ–°é—»ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„æƒ…æŠ¥å¯¹è±¡
2. ä½¿ç”¨ {target_lang} è¯­è¨€è¾“å‡ºæ‰€æœ‰æ–‡æœ¬å­—æ®µ
3. å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON ç»“æ„ï¼ˆä¸å¯é—æ¼ä»»ä½•å­—æ®µï¼‰
4. ç›´æ¥è¿”å› JSON æ•°ç»„ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—

ğŸ“‹ **ä¸¥æ ¼çš„ JSON ç»“æ„æ¨¡æ¿**ï¼ˆæ¯æ¡æ–°é—»å¿…é¡»åŒ…å«ä»¥ä¸‹æ‰€æœ‰å­—æ®µï¼‰ï¼š

```json
[
  {{
    "title": "ç®€çŸ­æ ‡é¢˜ï¼ˆ15å­—å†…ï¼‰",
    "fullTitle": "å®Œæ•´è¯¦ç»†æ ‡é¢˜ï¼ˆ25å­—å†…ï¼‰",
    "classification": "TOP SECRET | CONFIDENTIAL | RESTRICTED | UNCLASSIFIED",
    "impactLevel": "CRITICAL | HIGH | MEDIUM | INFO",
    "summary": "3-4å¥è¯çš„æƒ…æŠ¥æ‘˜è¦ï¼Œæè¿°äº‹ä»¶æ ¸å¿ƒã€å½±å“å’ŒèƒŒæ™¯",
    "relations": [
      {{
        "label": "ç›¸å…³å®ä½“åç§°ï¼ˆå¦‚å…¬å¸/å›½å®¶/æŠ€æœ¯ï¼‰",
        "type": "entity | tech | risk | resource",
        "desc": "ç®€çŸ­æè¿°ï¼ˆ10å­—å†…ï¼‰"
      }}
    ],
    "analysis": {{
      "strategic": [
        "æˆ˜ç•¥åˆ†æè¦ç‚¹1ï¼ˆ20-30å­—ï¼‰",
        "æˆ˜ç•¥åˆ†æè¦ç‚¹2ï¼ˆ20-30å­—ï¼‰"
      ]
    }},
    "investment": {{
      "action": "LONG | SHORT",
      "asset": "å…·ä½“æ ‡çš„ï¼ˆå¦‚è‚¡ç¥¨ä»£ç /èµ„äº§ç±»åˆ«ï¼‰",
      "risk": "HIGH | MEDIUM | LOW",
      "thesis": "æŠ•èµ„é€»è¾‘ï¼ˆ30-50å­—ï¼‰"
    }},
    "confidence": 85
  }}
]
```

âš ï¸ **å…³é”®çº¦æŸ**ï¼š
- `relations` æ•°ç»„ï¼šæ¯æ¡æ–°é—»è‡³å°‘3ä¸ªã€æœ€å¤š5ä¸ªå…³è”å®ä½“
- `analysis.strategic` æ•°ç»„ï¼šå¿…é¡»åŒ…å«2æ¡æˆ˜ç•¥åˆ†æ
- `confidence` å€¼ï¼šå¿…é¡»æ˜¯ 80-98 ä¹‹é—´çš„æ•´æ•°
- æ‰€æœ‰æ–‡æœ¬ä½¿ç”¨ {target_lang} è¯­è¨€
- ä¸è¦åŒ…å« `image` å’Œ `id` å­—æ®µï¼ˆè¿™äº›ç”±è„šæœ¬è‡ªåŠ¨æ·»åŠ ï¼‰

ğŸš€ **ç°åœ¨å¼€å§‹åˆ†æï¼Œç›´æ¥è¾“å‡º JSON æ•°ç»„**ï¼š
"""
        return prompt
    
    @staticmethod
    def _get_unsplash_image(keyword: str) -> str:
        """ç”Ÿæˆ Unsplash å›¾ç‰‡ URL"""
        keyword_encoded = keyword.replace(" ", "%20")
        return f"https://images.unsplash.com/photo-{random.randint(1500000000000, 1700000000000)}?q=80&w=800&auto=format&fit=crop&ixlib=rb-4.0.3&keyword={keyword_encoded}"


# ============== ä¸»å‡½æ•° ==============
def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    print("=" * 60)
    print("ğŸ”® NEXUS INTEL æ–°é—»è‡ªåŠ¨æ›´æ–°ç³»ç»Ÿ")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ API Key
    if not GEMINI_API_KEY:
        print("âŒ é”™è¯¯ï¼šGEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("ğŸ’¡ è¯·è¿è¡Œï¼šexport GEMINI_API_KEY='your_api_key_here'")
        return
    
    # 2. æŠ“å–æ–°é—»
    print("\nğŸ“¡ æŠ“å–æ–°é—»æº...")
    articles = NewsSource.fetch_from_rss()  # ä¼˜å…ˆä½¿ç”¨ RSSï¼ˆå…è´¹ï¼‰
    
    if not articles:
        print("âŒ æ— æ³•è·å–æ–°é—»ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        articles = NewsSource._generate_mock_news(NEWS_COUNT)
    
    print(f"âœ… æˆåŠŸè·å– {len(articles)} æ¡æ–°é—»")
    
    # 3. AI åˆ†æ
    analyzer = GeminiAnalyzer(GEMINI_API_KEY)
    
    # ç”Ÿæˆä¸‰ç§è¯­è¨€çš„æ•°æ®
    all_data = {}
    for lang in ["zh", "en", "es"]:
        print(f"\nğŸŒ ç”Ÿæˆ {lang} è¯­è¨€æ•°æ®...")
        lang_data = analyzer.analyze_batch(articles, lang)
        all_data[lang] = lang_data
    
    # 4. ä¿å­˜ JSON
    if any(all_data.values()):
        os.makedirs("public", exist_ok=True)
        
        output_data = {
            "generated_at": datetime.now().isoformat(),
            "version": "1.0",
            "languages": all_data
        }
        
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ° {OUTPUT_PATH}")
        print(f"ğŸ“Š ç»Ÿè®¡ï¼š")
        for lang, data in all_data.items():
            print(f"   - {lang}: {len(data)} æ¡")
    else:
        print("\nâŒ æ‰€æœ‰è¯­è¨€æ•°æ®ç”Ÿæˆå¤±è´¥")
    
    print("\n" + "=" * 60)
    print("âœ¨ æ›´æ–°å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    main()
